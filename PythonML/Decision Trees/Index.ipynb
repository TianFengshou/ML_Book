{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树\n",
    "### 分类决策树\n",
    "\n",
    "**参数:** \n",
    " - criterion{“gini”, “entropy”}, 默认为”gini”;分割判断标准,基尼或者信息熵\n",
    " \n",
    " - splitter{“best”, “random”}, 默认为”best”;分割策略,最佳或者随机\n",
    " \n",
    " - max_depth:int, 默认为None;树的最大深度,直到所有叶子都是纯净的,或者直到所有叶子都包含至少min_samples_split个样本。\n",
    " \n",
    " - min_samples_split:int or float, 默认为2;拆分内部节点所需的最少样本数,如果为整数则表示最小样本数,如果为float则表示百分比,ceil(min_samples_split * n_samples)\n",
    " \n",
    " - min_samples_leaf:int or float, 默认为1;在叶节点处需要的最小样本数。仅在任何深度的分裂点在min_samples_leaf左分支和右分支中的每个分支上至少留下训练样本时，才考虑。这可能具有平滑模型的效果，尤其是在回归中。如果为整数则表示最小样本数,如果为float则表示百分比ceil(min_samples_leaf*min_samples_leaf)\n",
    " \n",
    " - min_weight_fraction_leaf:float, 默认为0.0;在所有叶节点处（所有输入样本）的权重总和中的最小加权分数。如果未提供sample_weight，则样本的权重相等。\n",
    " \n",
    " - max_features:int, float or {“auto”, “sqrt”, “log2”}, 默认为None;寻找最佳分割时要考虑的功能数量：如果为int，则max_features在每个拆分处考虑要素。如果为float，max_features则为小数，并 在每次拆分时考虑要素。int(max_features * n_features)。如果“自动”，则max_features=sqrt(n_features)。如果是“ sqrt”，则max_features=sqrt(n_features)。如果为“ log2”，则为max_features=log2(n_features)。如果没有，则max_features=n_features。注意：直到找到至少一个有效的节点样本分区，分割的搜索才会停止，即使它需要有效检查多个max_features要素也是如此。\n",
    " \n",
    " - random_state:int, RandomState instance, 默认为None;随机数种子\n",
    " \n",
    " - max_leaf_nodes:int, 默认为None;以最佳的方式建立树。最佳节点定义为杂质的相对减少。如果为None，则叶节点数不受限制。\n",
    " \n",
    " - min_impurity_decrease:float, 默认为0.0;如果节点分裂导致杂质减少大于或等于该值，则该节点将分裂。\n",
    " \n",
    " - min_impurity_split：float, 默认为0;树木生长尽早停止的阈值。如果节点的杂质高于阈值，则该节点将分裂，否则为叶。将于0.25删除\n",
    " \n",
    " - class_weight:dict, list of dict or “balanced”, 默认为None。与形式的类有关的权重。“平衡”模式使用y的值来自动调整与输入数据中的类频率成反比的权重，如下所示： n_samples / (n_classes * np.bincount(y))。对于多输出，y的每一列的权重将相乘。请注意，如果指定了sample_weight，则这些权重将与sample_weight（通过fit方法传递）相乘。\n",
    " \n",
    " - presort:deprecated, 默认为’deprecated’;弃用，并将在v0.24删除\n",
    " \n",
    " - ccp_alpha:non-negative float, 默认为0.0;用于最小化成本复杂性修剪的复杂性参数。具有最大成本复杂度的子树小于ccp_alpha所选择的子树 。默认情况下，不执行修剪。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
       "       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=3.5,random_state=0,ccp_alpha=0.5)\n",
    "iris = load_iris()\n",
    "cross_val_score(clf, iris.data, iris.target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归决策树\n",
    "**参数:** \n",
    " - criterion：{“mse”, “friedman_mse”, “mae”}, default=”mse”，分割时的衡量标准\n",
    " - splitter:{“best”, “random”}, 默认为”best”;分割策略,最佳或者随机\n",
    " - max_depth:int, 默认为None;树的最大深度,知道所有叶子都是纯净的,或者直到所有叶子都包含至少min_samples_split个样本。\n",
    " - min_samples_split:int or float, 默认为2;拆分内部节点所需的最少样本数,如果为整数则表示最小样本数,如果为float则表示百分比,ceil(min_samples_split * n_samples)\n",
    " - min_samples_leaf:int or float, 默认为1;在叶节点处需要的最小样本数。仅在任何深度的分裂点在min_samples_leaf左分支和右分支中的每个分支上至少留下训练样本时，才考虑。这可能具有平滑模型的效果，尤其是在回归中。如果为整数则表示最小样本数,如果为float则表示百分比ceil(min_samples_leaf*min_samples_leaf)\n",
    " - min_weight_fraction_leaf:float, 默认为0.0;在所有叶节点处（所有输入样本）的权重总和中的最小加权分数。如果未提供sample_weight，则样本的权重相等。\n",
    " - max_features:int, float or {“auto”, “sqrt”, “log2”}, 默认为None;寻找最佳分割时要考虑的功能数量：如果为int，则max_features在每个拆分处考虑要素。如果为float，max_features则为小数，并 在每次拆分时考虑要素。int(max_features * n_features)。如果“自动”，则max_features=sqrt(n_features)。如果是“ sqrt”，则max_features=sqrt(n_features)。如果为“ log2”，则为max_features=log2(n_features)。如果没有，则max_features=n_features。注意：直到找到至少一个有效的节点样本分区，分割的搜索才会停止，即使它需要有效检查多个max_features要素也是如此。\n",
    " - random_state:int, RandomState instance, 默认为None;随机数种子\n",
    " - max_leaf_nodes:int, 默认为None;以最佳的方式建立树。最佳节点定义为杂质的相对减少。如果为None，则叶节点数不受限制。\n",
    " - min_impurity_decrease:float, 默认为0.0;如果节点分裂导致杂质减少大于或等于该值，则该节点将分裂。\n",
    " - min_impurity_split：float, 默认为0;树木生长尽早停止的阈值。如果节点的杂质高于阈值，则该节点将分裂，否则为叶。将于0.25删除\n",
    " - presort:deprecated, 默认为’deprecated’;弃用，并将在v0.24删除\n",
    " - ccp_alpha:non-negative float, 默认为0.0;用于最小化成本复杂性修剪的复杂性参数。具有最大成本复杂度的子树小于ccp_alpha所选择的子树 。默认情况下，不执行修剪。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39292219, -0.46749346,  0.02768473,  0.06441362, -0.50323135,\n",
       "        0.16437202,  0.11242982, -0.73798979, -0.30953155, -0.00137327])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "cross_val_score(regressor, X, y, cv=10)\n",
    "                   # doctest: +SKIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
