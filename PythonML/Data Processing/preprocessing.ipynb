{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  preprocessing\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                   [ 2.,  0.,  0.],\n",
    "                   [ 0.,  1., -1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化(Standardization)\n",
    "scale: 直接标准化\n",
    "\n",
    "StandardScaler,估计器格式的标准化类,更适合可视化编程需要的pipline.\n",
    " - copy : 是否copy元数据,默认为True.否则会直接改变原数据\n",
    " - with_mean : 是否在缩放前将数据居中,默认为True如果为True,transform时需要额外的矩阵进行运算,因此要注意内存问题.\n",
    " - with_std : 是否缩放到单位方差,默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = preprocessing.scale(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler(copy=True,with_mean=True,with_std=True).fit(X_train)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  2.],\n",
       "       [ 2.,  0.,  0.],\n",
       "       [ 0.,  1., -1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.44948974,  1.22474487, -0.26726124]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[-1., 1., 0.]]\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**缩放**\n",
    "**MinMaxScaler : 最大最小缩放**\n",
    "  - feature_range : 数据转换的范围,默认为(0,1)\n",
    "  - copy :是否复制,默认为True\n",
    "\n",
    "**MaxAbsScaler :最大绝对值缩放**\n",
    "  - copy : 是否复制,默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5, -1. ,  1. ],\n",
       "       [ 1. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. , -0.5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "X_train_maxabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用离群值缩放数据\n",
    "**RobustScaler:**\n",
    " - with_centering:是否数据居中,默认为True.如果为True,transform时需要额外的矩阵进行运算,因此要注意内存问题.\n",
    " - with_scaling:是够将数据缩放到四分位数范围,默认为True\n",
    " - copy : 是否复制,默认为True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -2. ,  0. ],\n",
       "       [-1. ,  0. ,  0.4],\n",
       "       [ 1. ,  0. , -1.6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "X = [[ 1., -2.,  2.],\n",
    "     [ -2.,  1.,  3.],\n",
    "     [ 4.,  1., -2.]]\n",
    "transformer = RobustScaler().fit(X)\n",
    "transformer\n",
    "\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非线性变换\n",
    "## 均匀分布\n",
    "\n",
    "**分位数转换方法:QuantileTransformer**\n",
    " - n_quantiles:要计算的分位数。默认值= 1000或n_samples.它对应于用于离散化累积分布函数的界标数。如果n_quantiles大于样本数，则将n_quantiles设置为样本数，因为较大的分位数不能更好地近似累积分布函数估计量。\n",
    " - output_distribution: 转换后的边际分布,uniform或者normal,默认uniform.通过设置为normal,也可以将数据映射到正态分布\n",
    " - ignore_implicit_zeros:仅适用于稀疏矩阵。默认为True，则将丢弃矩阵的稀疏条目以计算分位数统计信息。如果为False，则将这些条目视为零。\n",
    " - subsample:用于估计分位数以提高计算效率的最大样本数。默认为1e5.注意，对于值相同的稀疏矩阵和密集矩阵，子采样过程可能有所不同.\n",
    " - random_state:确定用于二次采样和平滑噪声的随机数生成。近似于随机数种子,默认为None\n",
    " - copy : 是否复制,默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonttian/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (112). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.3, 5.1, 5.8, 6.5, 7.9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "X_train_trans = quantile_transformer.fit_transform(X_train)\n",
    "X_test_trans = quantile_transformer.transform(X_test)\n",
    "np.percentile(X_train[:, 0], [0, 25, 50, 75, 100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯分布\n",
    "**幂转换:PowerTransformer**\n",
    " - method: 转换的方法,目前支持\"yeo-johnson\"和\"box-cox\"\n",
    " - standardize: boolean, 默认为True,设置后可进行零均值,单位方差归一化应用于转换后的输出\n",
    " - copy : 是否复制,默认为True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49024349,  0.17881995, -0.1563781 ],\n",
       "       [-0.05102892,  0.58863195, -0.57612415],\n",
       "       [ 0.69420009, -0.84857822,  0.10051454]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = preprocessing.PowerTransformer(method='box-cox', standardize=False)\n",
    "X_lognormal = np.random.RandomState(616).lognormal(size=(3, 3))\n",
    "X_lognormal\n",
    "\n",
    "pt.fit_transform(X_lognormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 规范化(Normalization)\n",
    "规范化,或者翻译为正则化,其是将单个样本缩放为具有单位范数的过程.如果计划使用点积或任何其他核的二次形式来量化任何一对样本的相似性，则此过程可能会很有用。\n",
    "**normalize**\n",
    " - norm:\"l1\",\"l2\",\"max\"\n",
    " - axis: 0 or 1 .默认为1\n",
    " - copy:是够拷贝数据,默认为True\n",
    " - return_norm:是否返回计算的范数,默认为False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalizer(copy=True, norm='l2')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.transform(X)\n",
    "\n",
    "normalizer.transform([[-1.,  1., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码类别特征\n",
    "序数编码器：将分类特征编码为整数数组。该转换器的输入应为整数或字符串之类的数组，表示分类（离散）特征所采用的值。要素将转换为序数整数。这将导致每个要素的一列整数（0到n_categories-1）。\n",
    "**OrdinalEncoder**\n",
    " - categories:默认为\"auto\":根据训练数据自动确定类别。也可以输入一个list:categories[i]在第ith列中包含期望的类别。传递的类别不应将字符串和数字值混合使用，并且在使用数字值时应进行排序。\n",
    " - dtype:所需的输出dtype。默认:np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "# Note that for there are missing categorical values for the 2nd and 3rd\n",
    "# feature\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "\n",
    "\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHotEncoder**\n",
    "该转换器的输入应为整数或字符串之类的数组，表示分类（离散）特征所采用的值。使用单热（也称为“ one-of-K”或“ dummy”）编码方案对特征进行编码。这将为每个类别创建一个二进制列，并返回一个稀疏矩阵或密集数组（取决于sparse 参数）\n",
    "**参数**\n",
    " - categories:默认为\"auto\":根据训练数据自动确定类别。也可以输入一个list:categories[i]在第ith列中包含期望的类别。传递的类别不应将字符串和数字值混合使用，并且在使用数字值时应进行排序。\n",
    " - drop:可选-{if_binary,first}或者一个数组,默认为None.指定一种用于删除每个功能类别之一的方法。这在完美共线特征导致问题的情况下很有用，例如将结果数据输入到神经网络或不规则回归时。但是，删除一个类别会破坏原始表示形式的对称性，因此可能在下游模型（例如，惩罚线性分类或回归模型）中引起偏差。无：保留所有功能（默认）。'first'：删除每个功能中的第一个类别。如果仅存在一个类别，则该功能将被完全删除。'if_binary'：删除具有两个类别的每个功能中的第一个类别。具有1个或2个以上类别的要素保持不变。\n",
    " - sparse:默认为为True，将返回稀疏矩阵，否则将返回数组。\n",
    " - dtype:输入数据的类型,默认为np.float\n",
    " - handle_unknown:{‘error’, ‘ignore’}, default=’error’；是在转换过程中引发错误还是直接忽略存在的未知分类特征（默认为引发）。当此参数设置为“忽略”并且在转换过程中遇到未知类别时，此功能生成的一键编码列将全为零。在逆变换中，未知类别将表示为“无”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "enc.fit(X)\n",
    "\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['Female', 1], ['Male', 4]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Male', 1],\n",
       "       [None, 2]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names(['gender', 'group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 离散\n",
    "离散化 （也称为量化或合并）提供了一种将连续特征划分为离散值的方法。具有离散特征的某些数据集可能会受益于离散化，因为离散化可以将连续属性的数据集转换为仅具有名义属性的数据集。\n",
    "一键编码的离散化特征可以使模型更具表现力，同时保持可解释性。例如，使用离散器的预处理可以将非线性引入线性模型。\n",
    "**K-bins离散化:KBinsDiscretizer**\n",
    " - n_bin :产生间隔的数量,默认为5\n",
    " - encode:用于编码的方法,可选{‘onehot’, ‘onehot-dense’, ‘ordinal’}, (default=’onehot’)\n",
    " - strategy:用于定义间隔宽度的方法-{‘uniform’, ‘quantile’, ‘kmeans’}, (default=’quantile’).uniform:相同宽度,quantile:分位数,kmeans:基于一维kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [2., 2., 2., 1.],\n",
       "       [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[-2, 1, -4,   -1],\n",
    "     [-1, 2, -3, -0.5],\n",
    "     [ 0, 3, -2,  0.5],\n",
    "     [ 1, 4, -1,    2]]\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "est.fit(X)\n",
    "\n",
    "Xt = est.transform(X)\n",
    "Xt  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征二值化是阈值化数字特征以获得布尔值的过程。\n",
    "\n",
    "**特征二值化:Binarizer**\n",
    " - threshold:阈值,低于此阈值的将编码为0,高于该阈值的将编码为1.默认为0\n",
    " - copy:布尔,默认为True;设置为False将执行就地二进制化并避免复制（如果输入已经是numpy数组或scipy.sparse CSR矩阵）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binarizer(copy=True, threshold=0.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "\n",
    "binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing\n",
    "binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成多项式特征\n",
    "生成由小于或等于指定度的特征的所有多项式组合组成的新特征矩阵。例如，如果输入样本是二维且格式为[a，b]，则2阶多项式特征为[1，a，b，a ^ 2，ab，b ^ 2]。\n",
    "**生成多项式和交互特征:PolynomialFeatures**\n",
    " - degree:度,默认为2.生成多项式特征的程度\n",
    " - interaction_only:如果为True(default),则只有相互作用特征产生,自身不会产生多次方的特征如x_1的二次方,x_2三次方等等\"\n",
    " - include_bias:默认为True,包含一个偏差项,该特征中所有多项式幂均为零.\n",
    " - order:从{'C'，'F'}中选择,默认为C.在密集情况下输出数组的顺序。“ F”阶的计算速度更快，但可能会减慢后续的估计量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
