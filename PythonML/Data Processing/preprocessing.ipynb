{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  preprocessing\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                   [ 2.,  0.,  0.],\n",
    "                   [ 0.,  1., -1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化(Standardization)\n",
    "scale: 直接标准化\n",
    "\n",
    "StandardScaler,估计器格式的标准化类,更适合可视化编程需要的pipline.\n",
    " - copy : 是否copy元数据,默认为True.否则会直接改变原数据\n",
    " - with_mean : 是否在缩放前将数据居中,默认为True如果为True,transform时需要额外的矩阵进行运算,因此要注意内存问题.\n",
    " - with_std : 是否缩放到单位方差,默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = preprocessing.scale(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler(copy=True,with_mean=True,with_std=True).fit(X_train)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  2.],\n",
       "       [ 2.,  0.,  0.],\n",
       "       [ 0.,  1., -1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.44948974,  1.22474487, -0.26726124]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[-1., 1., 0.]]\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**缩放**\n",
    "**MinMaxScaler : 最大最小缩放**\n",
    "  - feature_range : 数据转换的范围,默认为(0,1)\n",
    "  - copy :是否复制,默认为True\n",
    "\n",
    "**MaxAbsScaler :最大绝对值缩放**\n",
    "  - copy : 是否复制,默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5, -1. ,  1. ],\n",
       "       [ 1. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. , -0.5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "X_train_maxabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用离群值缩放数据\n",
    "**RobustScaler:**\n",
    " - with_centering:是否数据居中,默认为True.如果为True,transform时需要额外的矩阵进行运算,因此要注意内存问题.\n",
    " - with_scaling:是够将数据缩放到四分位数范围,默认为True\n",
    " - copy : 是否复制,默认为True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -2. ,  0. ],\n",
       "       [-1. ,  0. ,  0.4],\n",
       "       [ 1. ,  0. , -1.6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "X = [[ 1., -2.,  2.],\n",
    "     [ -2.,  1.,  3.],\n",
    "     [ 4.,  1., -2.]]\n",
    "transformer = RobustScaler().fit(X)\n",
    "transformer\n",
    "\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非线性变换\n",
    "## 均匀分布\n",
    "\n",
    "**分位数转换方法:QuantileTransformer**\n",
    " - n_quantiles:要计算的分位数。默认值= 1000或n_samples.它对应于用于离散化累积分布函数的界标数。如果n_quantiles大于样本数，则将n_quantiles设置为样本数，因为较大的分位数不能更好地近似累积分布函数估计量。\n",
    " - output_distribution: 转换后的边际分布,uniform或者normal,默认uniform.通过设置为normal,也可以将数据映射到正态分布\n",
    " - ignore_implicit_zeros:仅适用于稀疏矩阵。默认为True，则将丢弃矩阵的稀疏条目以计算分位数统计信息。如果为False，则将这些条目视为零。\n",
    " - subsample:用于估计分位数以提高计算效率的最大样本数。默认为1e5.注意，对于值相同的稀疏矩阵和密集矩阵，子采样过程可能有所不同.\n",
    " - random_state:确定用于二次采样和平滑噪声的随机数生成。近似于随机数种子,默认为None\n",
    " - copy : 是否复制,默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonttian/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (112). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.3, 5.1, 5.8, 6.5, 7.9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "X_train_trans = quantile_transformer.fit_transform(X_train)\n",
    "X_test_trans = quantile_transformer.transform(X_test)\n",
    "np.percentile(X_train[:, 0], [0, 25, 50, 75, 100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯分布\n",
    "**幂转换:PowerTransformer**\n",
    " - method: 转换的方法,目前支持\"yeo-johnson\"和\"box-cox\"\n",
    " - standardizeboolean: 默认为True,设置后可进行零均值,单位方差归一化应用于转换后的输出\n",
    " - copy : 是否复制,默认为True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49024349,  0.17881995, -0.1563781 ],\n",
       "       [-0.05102892,  0.58863195, -0.57612415],\n",
       "       [ 0.69420009, -0.84857822,  0.10051454]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = preprocessing.PowerTransformer(method='box-cox', standardize=False)\n",
    "X_lognormal = np.random.RandomState(616).lognormal(size=(3, 3))\n",
    "X_lognormal\n",
    "\n",
    "pt.fit_transform(X_lognormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 规范化(Normalization)\n",
    "规范化,或者翻译为正则化,其是将单个样本缩放为具有单位范数的过程.如果计划使用点积或任何其他核的二次形式来量化任何一对样本的相似性，则此过程可能会很有用。\n",
    "**normalize**\n",
    " - norm:\"l1\",\"l2\",\"max\"\n",
    " - axis: 0 or 1 .默认为1\n",
    " - copy:是够拷贝数据,默认为True\n",
    " - return_norm:是否返回计算的范数,默认为False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalizer(copy=True, norm='l2')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.transform(X)\n",
    "\n",
    "normalizer.transform([[-1.,  1., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码类别特征\n",
    "**OrdinalEncoder**\n",
    " - categories:默认为\"auto\":根据训练数据自动确定类别。也可以输入一个list:categories[i]在第ith列中包含期望的类别。传递的类别不应将字符串和数字值混合使用，并且在使用数字值时应进行排序。\n",
    " - dtype:所需的输出dtype。默认:np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "# Note that for there are missing categorical values for the 2nd and 3rd\n",
    "# feature\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "\n",
    "\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHotEncoder**\n",
    " - categories:默认为\"auto\":根据训练数据自动确定类别。也可以输入一个list:categories[i]在第ith列中包含期望的类别。传递的类别不应将字符串和数字值混合使用，并且在使用数字值时应进行排序。\n",
    " - drop:可选-if_binary,first或者一个数组,默认为None.作用为丢弃所选列\n",
    " - sparse:默认为为True，将返回稀疏矩阵，否则将返回数组。\n",
    " - dtype:输入数据的类型,默认为np.float\n",
    " - handle_unknown:是在转换过程中引发错误还是直接忽略存在的未知分类特征（默认为引发）。当此参数设置为“忽略”并且在转换过程中遇到未知类别时，此功能生成的一键编码列将全为零。在逆变换中，未知类别将表示为“无”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "enc.fit(X)\n",
    "\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['Female', 1], ['Male', 4]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Male', 1],\n",
       "       [None, 2]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names(['gender', 'group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 离散\n",
    "**K-bins离散化:KBinsDiscretizer**\n",
    " - n_bin :产生间隔的数量,默认为5\n",
    " - encode:用于编码的方法,可选{‘onehot’, ‘onehot-dense’, ‘ordinal’}, (default=’onehot’)\n",
    " - strategy:用于定义间隔宽度的方法-{‘uniform’, ‘quantile’, ‘kmeans’}, (default=’quantile’).uniform:相同宽度,quantile:分位数,kmeans:基于一维kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [2., 2., 2., 1.],\n",
       "       [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[-2, 1, -4,   -1],\n",
    "     [-1, 2, -3, -0.5],\n",
    "     [ 0, 3, -2,  0.5],\n",
    "     [ 1, 4, -1,    2]]\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "est.fit(X)\n",
    "\n",
    "Xt = est.transform(X)\n",
    "Xt  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征二值化是阈值化数字特征以获得布尔值的过程。\n",
    "\n",
    "**特征二值化:Binarizer**\n",
    " - threshold:阈值,低于此阈值的将编码为0,高于该阈值的将编码为1.默认为0\n",
    " - copy:是否拷贝,默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binarizer(copy=True, threshold=0.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "\n",
    "binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing\n",
    "binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成多项式技能\n",
    "生成由小于或等于指定度的特征的所有多项式组合组成的新特征矩阵。例如，如果输入样本是二维且格式为[a，b]，则2阶多项式特征为[1，a，b，a ^ 2，ab，b ^ 2]。\n",
    "**生成多项式和交互特征:PolynomialFeatures**\n",
    " - degree:度,默认为2.生成多项式特征的程度\n",
    " - interaction_only:如果为false,如果为True,则只有相互作用特征产生,自身不会产生多次方的特征如x_1的二次方,x_2三次方等等\n",
    " - include_bias:默认为True,包含一个偏差项,该特征中所有多项式幂均为零.\n",
    " - order:从{'C'，'F'}中选择,默认为C.在密集情况下输出数组的顺序。“ F”阶的计算速度更快，但可能会减慢后续的估计量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
