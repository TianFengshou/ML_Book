{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT 调参指南\n",
    "\n",
    "## 初始化\n",
    " \n",
    " 1. 使用默认参数。默认学习率-0.1\n",
    " 2. 子采样（subsample）典型值-[0.5,0.8]\n",
    " \n",
    " \n",
    "## 调参步骤\n",
    "\n",
    " 1. 网格搜索-寻找最佳迭代次数？\n",
    " 2. 网格搜索，寻找最佳最大深度（max_depth）以及 子叶最小分裂阈值（min_samples_split）（参与寻找，但是因为和其他参数关联，暂时不确定）\n",
    " 3. 网格搜索-同时确认最小节点分裂阈值与 终点节点最小样本数（min_samples_leaf）\n",
    " 4. 网格搜索-寻找最大特征数（max_features）\n",
    " 5. 网格搜索-寻找最佳子采样比例（subsample）\n",
    " 6. 已经确定最佳模型，开始减半步长，增加迭代次数，来提高泛化能力。不断尝试直到出现泛华能力下降（过拟合）\n",
    "\n",
    "## 最终模型\n",
    "\n",
    "```python\n",
    "GradientBoostingClassifier(learning_rate=0.01, \n",
    "                           n_estimators=600,\n",
    "                           max_depth=7, \n",
    "                           min_samples_leaf =60, \n",
    "                           min_samples_split =1200,\n",
    "                           max_features=9, \n",
    "                           subsample=0.7, \n",
    "                           random_state=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM调参指南 \n",
    "\n",
    "## 初始化\n",
    "\n",
    " 1. 最大特征数（max_ features），典型值-[0.3-0.4],或者 ‘sqrt'\n",
    " 2. 子叶最小分裂阈值（min_ samples_ split），推荐总样本数的[0.5%,1%],不均等分类问题，请选择较小的数值，本处——500.\n",
    " 3. 子采样，推荐 0.8\n",
    " 4. 终点节点最小样本数（min_samples_leaf），凭感觉选择一个合适的数字，只要不会造成过拟合即可。因为不均等分类问题，奔出选择一个较小的值。50\n",
    " 5. max_depth.典型值[5.10],此处选择5.\n",
    " \n",
    " \n",
    " ## 模型调参\n",
    " \n",
    " \n",
    " 1. 固定学习率（0.1），网格搜索估测决策树数量\n",
    " 2. 调节树参数(网格搜索）\n",
    "     1. 调节max_depth和 num_samples_split\n",
    "     2. 调节min_samples_leaf\n",
    "     3. 调节max_features\n",
    " 3. 调节子样本比例\n",
    " 4. ，并降低learning rate，增加步长。确定最佳模型。\n",
    " \n",
    " \n",
    " ## 最终模型\n",
    "\n",
    "```python\n",
    "GradientBoostingClassifier(learning_rate=0.005, \n",
    "                           n_estimators=1500,\n",
    "                           max_depth=9, \n",
    "                           min_samples_split=1200, \n",
    "                           min_samples_leaf=60, \n",
    "                           subsample=0.85, \n",
    "                           random_state=10, \n",
    "                           max_features=7,\n",
    "                           warm_start=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB 调参指南\n",
    "\n",
    "## 基本介绍\n",
    "\n",
    "XGBoost的作者把所有的参数分成了三类：\n",
    "\n",
    " 1. 通用参数：宏观函数控制。\n",
    " 2. Booster参数：控制每一步的booster(tree/regression)。\n",
    " 3. 学习目标参数：控制训练目标的表现。\n",
    " \n",
    "## 调参步骤\n",
    "\n",
    " 1. 初始化预估决策树个数\n",
    " 2. 调节树的参数\n",
    "     1. 预估最大深度与终点节点最小样本占比的和\n",
    "     2. 预估gamma参数\n",
    "     3. 调整子采样与列采样比例\n",
    " 3. 调整正则化系数\n",
    " 4. 减少学习率，增加决策树数量以确定最佳模型。\n",
    " \n",
    "## 初始化，预估决策树个数\n",
    " \n",
    " 1. 学习率（eta），典型值[0.01，0.2]，这里选择0.1\n",
    " 2. min_child_weight --- 终点节点最小样本占比 的 和 默认等于一，使用默认选择\n",
    " 3. 最大深度（max_depth）x，此处选择-5，典型值[4，6]\n",
    " 4. gamma，典型值[0.1,0.2]，此处默认零，之后需要调整。\n",
    " 5. 子采样，列采样 = 0.8 ，典型值[0.5,0.9]\n",
    " 6. scale_pos_weight,不平衡时加快瘦脸，此处选1\n",
    " 7. 使用网格搜索，预估决策树个数，策略如下\n",
    " \n",
    "\n",
    "## 对树的参数进行调节\n",
    "### 预估最大深度（max_depth）与终点节点最小样本占比 的 和（min_child_weight）\n",
    "\n",
    "第一步，初步估计\n",
    "```python\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(\n",
    "    learning_rate =0.1, \n",
    "    n_estimators=140, \n",
    "    max_depth=5,\n",
    "    min_child_weight=1, \n",
    "    gamma=0, \n",
    "    subsample=0.8,             \n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic', \n",
    "    nthread=4,     \n",
    "    scale_pos_weight=1, \n",
    "    seed=27), \n",
    "                        param_grid = param_test1,     \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=4,iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "```\n",
    "第二步骤，减少步长预估，逐步寻找\n",
    "\n",
    "```python\n",
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "```\n",
    "\n",
    "### gamma 参数调优\n",
    "\n",
    "具体含义：\n",
    " - 在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值。\n",
    " - 这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。\n",
    " \n",
    "代码：\n",
    "```python\n",
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "```\n",
    "### 调整子采样（subsample）与列采样 （colsample_bytree)\n",
    "```python\n",
    "# 第一次估计，步长0.1\n",
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "# 第二次估计，步长0.05\n",
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "```\n",
    "\n",
    "## 调整正则化参数\n",
    "gamma本身已经提过了一种有效的降低过拟合的方法，但是这里我们仍然进行正则化参数的调整。下面是alpha的网格搜索，lambda同理。\n",
    "```python\n",
    "# 第一次估计\n",
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "# 第二次估计\n",
    "param_test7 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "```\n",
    "\n",
    "## 降低学习率，增加拟合次数，确定最终模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存在的问题\n",
    "### 参数估计\n",
    " 1. 终点节点样本占比问题- min_ weight_ fraction_leaf？&& 终点节点样本数量问题 - max_ leaf_ nodes ？"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
