{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机\n",
    "\n",
    "支持向量机（SVM）是一套用于分类， 回归和离群值检测的监督学习方法。\n",
    "\n",
    "### 分类\n",
    "#### SVC\n",
    "\n",
    "该实现基于libsvm。拟合时间至少与样本数量成平方比例，超过成千上万的样本可能不切实际。对于大型数据集，请考虑使用sklearn.svm.LinearSVC或 sklearn.linear_model.SGDClassifier代替，可能在 sklearn.kernel_approximation.Nystroem变压器之后。多类支持根据一对一方案进行处理。\n",
    "\n",
    "**参数**\n",
    "\n",
    "\n",
    "- C:default=0;正则化参数。正则化的强度与C成反比。必须严格为正。惩罚是平方的l2惩罚。\n",
    " \n",
    "- kernel:核{'linear'，'poly'，'rbf'，'sigmoid'，'precomputed'}，默认='rbf';指定算法中要使用的内核类型。它必须是“线性”，“多边形”，“ rbf”，“ Sigmoid”，“预先计算”或可调用之一。如果没有给出，将使用“ rbf”。如果给出了可调用对象，则将其用于根据数据矩阵预先计算内核矩阵；那个矩阵应该是一个形状的数组。(n_samples, n_samples)。\n",
    " \n",
    "- degree:多项式内核函数的度,默认为3,其他核将会忽略该参数。\n",
    " \n",
    "- gamma:{'scale'，'auto'}或float，默认='scale';“ rbf”，“ poly”和“ Sigmoid”的内核系数。如果gamma='scale'（默认）通过，则它将1 /（n_features * X.var（））用作gamma值;如果为'auto'，则使用1 / n_features。\n",
    " \n",
    "- coef0:float,默认为0;内核函数中的独立术语,该参数仅在ploy和sigmoid中有意义。\n",
    " \n",
    "- shrinking:默认为True,是否启用缩小的启发式方法。\n",
    " \n",
    "- probability:默认为False,是否启用概率估计,必须在调用器启动此功能的fit,因为该方法在内部使用五倍交叉验证,因此predict_proba将会被predict减慢速度。\n",
    " \n",
    "- tol:默认为1e-3,停止标准的公差。\n",
    " \n",
    "- cache_size:指定内核缓存的大小（以MB为单位），默认200。\n",
    " \n",
    "- class_weight:dict或“ balanced”，默认=无；class_weight[i]*C对于SVC ，将类i的参数C设置为。如果未给出，则所有类均应具有权重一。“平衡”模式使用y的值来自动调整与输入数据中的类频率成反比的权重。n_samples / (n_classes * np.bincount(y))。\n",
    " \n",
    "- verbose:默认为False,是否启用详细输出,如果启用,则可能无法在多线程上下中正常工作。\n",
    " \n",
    "- max_iter:对求解器内的迭代进行硬性限制，或者为-1（无限制）。默认-1。\n",
    " \n",
    "- decision_function_shape:{‘ovo’, ‘ovr’}, default=’ovr’。\n",
    " \n",
    "- break_ties:默认False;如果为真，decision_function_shape='ovr'以及类 > 2号， 预计将根据置信值打破僵局 decision_function ; 否则，将返回绑定类中的第一类。请注意，与简单预测相比，打破平局的计算成本较高。\n",
    " \n",
    "- random_state:默认为None,随机数种子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NuSVC**\n",
    "效果与SVC一样,但参数不同\n",
    "\n",
    "**多类分类问题**\n",
    "SVC与NuSVC采用OVO策略,LineearSVC采用OVR策略\n",
    "\n",
    "#### LinearSVC\n",
    "\n",
    "类似于带有参数kernel ='linear'的SVC，但是是根据liblinear而不是libsvm来实现的，因此它在选择罚分和损失函数时具有更大的灵活性，并且应该更好地扩展到大量样本。此类同时支持密集输入和稀疏输入，并且根据“一对多”方案处理多类支持。\n",
    "\n",
    "**参数:**\n",
    "\n",
    " - penalty:{'l1','l2'},默认'l2';惩罚项。\n",
    " - loss:{‘hinge’, ‘squared_hinge’}, default=’squared_hinge’;损失值。\n",
    " - dual:选择算法来解决对偶或原始优化问题,默认为Flase。当n_samples> n_features时，首选dual = False。\n",
    " - tol:默认1e-4,停止标准的公差。\n",
    " - C:浮点数,默认1；正则化参数。正则化的强度与C成反比。必须严格为正。\n",
    " - multi_class:{' ovr '，'crammer_singer'}，默认='ovr';多分类策略。\n",
    " - fit_intercept:是否计算此模型的截距。如果设置为false，则在计算中将不使用截距（即，数据应已居中）。\n",
    " - intercept_scaling:float,默认为1;当self.fit_intercept为True时，实例向量x变为[x，self.intercept_scaling]，即，将具有等于intercept_scaling的恒定值的“合成”特征附加到实例向量。 截距变为intercept_scaling *综合特征权重注意！ 与所有其他特征一样，合成特征权重也要经过l1 / l2正则化。 为了减轻正则化对合成特征权重（以及因此对截距）的影响，必须增加intercept_scaling。\n",
    " - class_weight:dict,\"balanced\",None;参数C的权重,默认为None,权重都为1;“平衡”模式使用y的值来自动调整与输入数据中的类频率成反比的权重。具体公式为:n_samples / (n_classes * np.bincount(y))。\n",
    " - verbose:默认0,不启用详细输出,启用可能无法在多线程上下文中正常工作。\n",
    " - random_state:int或RandomState实例.默认为None。\n",
    " - max_iter:要运行的最大迭代次数,默认1000。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('linearsvc',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=0,\n",
       "                           tol=1e-05, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_features=4, random_state=0)\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.141443   0.52678403 0.67978681 0.49307509]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.named_steps['linearsvc'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16935944]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.named_steps['linearsvc'].intercept_)\n",
    "\n",
    "print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归\n",
    "#### SVR\n",
    "该实现基于libsvm。拟合时间的复杂度是样本数量的两倍以上，这使得很难扩展到具有多个10000个样本的数据集。对于大型数据集，请考虑使用sklearn.svm.LinearSVR或 sklearn.linear_model.SGDRegressor代替.\n",
    "\n",
    "\n",
    "**参数**\n",
    " - kernel:{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’;支持向量机所使用的内核。\n",
    " - degree:int,default=3;多项式内核函数的度(degree)（“ poly”）。被所有其他内核忽略。\n",
    " - gamma:{'scale'，'auto'}或float，默认='scale'; rbf”，“ poly”和“ Sigmoid”的内核系数。如果gamma='scale'（默认）通过，则它将1 /（n_features * X.var（））用作gamma值，如果为'auto'，则使用1 / n_features。\n",
    " - coef0:float,默认0,;内核函数中的独立术语,仅在\"ploy\"和\"sigmoid\"中有意义。\n",
    " - tol:float,默认1e-3;停止标准的公差。\n",
    " - C:浮点数,默认1;正则化参数,正则化强度与C成正比,必须严格为正。\n",
    " - epsilon:float,默认0.1;epslion-SVR中的Epsilon.指定在训练损失函数中没有惩罚项的epsilon-tube,该点与实际值之间的距离为epsilon。\n",
    " - shrinking:bool,默认True；是否使用缩小的启发式方法。\n",
    " - cache_size:制定内核缓存大小,默认200(单位MB)。\n",
    " - verbose:是否启用详细输出。\n",
    " - max_iter:对求解器内的迭代进行硬性限制,或者为-1(默认,意为无限制)。\n",
    " - decision_function_shape：{‘ovo’, ‘ovr’}, default=’ovr’；是否返回形状（n_samples，n_classes）的一对一休息（'ovr'）决策函数作为所有其他分类器，还是返回形状为（n_samples）的libsvm原始的一对一（'ovo'）决策函数，n_classes *（n_classes-1）/ 2）。但是，始终将“一对一”（'ovo'）用作多类别策略。对于二进制分类，将忽略该参数。\n",
    " - break_ties：bool，默认= False；如果为真，decision_function_shape='ovr'以及类> 2号， 预计将根据置信值打破僵局 decision_function ; 否则，返回绑定类中的第一类。请注意，与简单预测相比，打破平局的计算成本较高。\n",
    " - random_state：随机数种子，默认为None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svr',\n",
       "                 SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "n_samples, n_features = 10, 5\n",
    "rng = np.random.RandomState(0)\n",
    "y = rng.randn(n_samples)\n",
    "X = rng.randn(n_samples, n_features)\n",
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR \n",
    "线性支持向量回归。\n",
    "\n",
    "类似于带有参数kernel ='linear'的SVR，但是是根据liblinear而不是libsvm来实现的，因此它在选择罚分和损失函数时具有更大的灵活性，并且应更好地扩展到大量样本。此类同时支持密集输入和稀疏输入。\n",
    "\n",
    "**参数**\n",
    " - epsilon:float,默认0;ε不敏感损失函数中的Epsilon参数。注意，该参数的值取决于目标变量y的小数位数。如果不确定，请设置epsilon=0。\n",
    " - tol:float,默认1e-4;停止标准的公差\n",
    " - C:float,默认1.0;正则化参数。正则化的强度与C成反比。必须严格为正。\n",
    " - loss:{'epsilon_insensitive'，'squared_epsilon_insensitive'}，默认='epsilon_insensitive';指定损失函数。ε不敏感损失（标准SVR）为L1损失，ε不敏感平方损失（“ squared_epsilon_insensitive”）为L2损失。\n",
    " - fit_intercept:bool,默认True;是否计算此模型的截距。如果设置为false，则在计算中将不使用截距（即，数据应已居中）。\n",
    " - intercept_scaling:float,默认1;当self.fit_intercept为True时，实例向量x变为[x，self.intercept_scaling]，即，将具有等于intercept_scaling的恒定值的“合成”特征附加到实例向量。截距变为intercept_scaling *综合特征权重注意！与所有其他特征一样，合成特征权重也要经过l1 / l2正则化。为了减轻正则化对合成特征权重（以及因此对截距）的影响，必须增加intercept_scaling。\n",
    " - dual:bool,默认true;选择算法来解决对偶或原始优化问题。当n_samples> n_features时，首选dual = False。\n",
    " - verbose:int,默认0;是否详细展示\n",
    " - random_state:int或者RandomState,默认None;随机数种子\n",
    " - max_iter:int,默认1000;最大迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('linearsvr',\n",
       "                 LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "                           intercept_scaling=1.0, loss='epsilon_insensitive',\n",
       "                           max_iter=1000, random_state=0, tol=1e-05,\n",
       "                           verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, random_state=0)\n",
    "regr = make_pipeline(StandardScaler(),\n",
    "                     LinearSVR(random_state=0, tol=1e-5))\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.58284419 27.02366194 44.35792369 64.52256231]\n",
      "[-4.]\n",
      "[-2.38421844]\n"
     ]
    }
   ],
   "source": [
    "print(regr.named_steps['linearsvr'].coef_)\n",
    "\n",
    "print(regr.named_steps['linearsvr'].intercept_)\n",
    "\n",
    "print(regr.predict([[0, 0, 0, 0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
